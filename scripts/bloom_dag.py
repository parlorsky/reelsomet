"""
Bloom Video Production DAG.

Automated pipeline: ideas ‚Üí scripts ‚Üí TTS ‚Üí timestamps ‚Üí render ‚Üí deliver.
Runs up to 3 video pipelines in parallel.

Usage:
    # As CLI
    python scripts/bloom_dag.py --count 5 --format story

    # As module (from bot)
    from bloom_dag import run_dag
    results = await run_dag(count=5, format="story", on_progress=callback)
"""

import asyncio
import json
import logging
import os
import random
import re
import shutil
import subprocess
import sys
import tempfile
from dataclasses import dataclass, field, asdict
from datetime import datetime
from pathlib import Path
from typing import Callable, Optional

logger = logging.getLogger(__name__)

# Add scripts dir to path for imports
sys.path.insert(0, str(Path(__file__).parent))
from llm_client import chat_json

# Project root
PROJECT_ROOT = Path(__file__).parent.parent
DOWNLOADS_DIR = PROJECT_ROOT / "downloads"
OUTPUT_DIR = PROJECT_ROOT / "output"
DATA_DIR = PROJECT_ROOT / "data"
SCRIPTS_DIR = PROJECT_ROOT / "scripts"
CATALOG_FILE = PROJECT_ROOT / "input" / "scripts_catalog.json"
DRAFT_FILE = PROJECT_ROOT / "input" / "scripts_catalog_draft.json"
LOG_FILE = DATA_DIR / "dag_log.json"
BG_CATALOG = PROJECT_ROOT / "input" / "backgrounds" / "catalog.json"
BG_DIR = PROJECT_ROOT / "input" / "backgrounds"
HOOKS_CATALOG = PROJECT_ROOT / "input" / "hooks" / "catalog.json"
HOOKS_DIR = PROJECT_ROOT / "input" / "hooks"
MUSIC_DIR = PROJECT_ROOT / "downloads" / "music"

MAX_PARALLEL = 3
VALID_FORMATS = {"story", "book", "micro", "challenge", "contrast", "debate", "mix"}


def _load_hook_info(hook_id: str) -> Optional[dict]:
    """Load hook metadata from catalog by ID."""
    if not HOOKS_CATALOG.exists():
        return None
    try:
        data = json.loads(HOOKS_CATALOG.read_text(encoding="utf-8"))
        for hook in data.get("hooks", []):
            if hook["id"] == hook_id:
                return hook
    except Exception:
        pass
    return None


# ---------------------------------------------------------------------------
# Data classes
# ---------------------------------------------------------------------------

@dataclass
class DagItem:
    id: int
    status: str = "pending"  # pending|idea|script|tts|timestamps|markup|rendering|done|failed
    title: str = ""
    format: str = "story"
    hook_type: Optional[str] = None
    idea: Optional[dict] = None
    script: Optional[dict] = None
    files: dict = field(default_factory=lambda: {
        "markup": None, "audio": None, "timestamps": None, "video": None, "bg_dir": None
    })
    instagram_caption: str = ""
    plain_text: str = ""
    tts_text: str = ""
    error: Optional[str] = None
    timings: dict = field(default_factory=dict)


@dataclass
class DagRun:
    id: str = ""
    status: str = "pending"  # pending|running|completed|failed
    requested_count: int = 0
    format: str = "story"
    items: list = field(default_factory=list)
    started_at: str = ""
    finished_at: str = ""


# ---------------------------------------------------------------------------
# ID management
# ---------------------------------------------------------------------------

def get_next_id() -> int:
    """Get next available script ID from catalogs."""
    max_id = 0
    for path in [CATALOG_FILE, DRAFT_FILE]:
        if path.exists():
            data = json.loads(path.read_text(encoding="utf-8"))
            entries = data.get("scripts", []) or data.get("drafts", []) or []
            for entry in entries:
                max_id = max(max_id, entry.get("id", 0))
    return max_id + 1


# ---------------------------------------------------------------------------
# DAG steps
# ---------------------------------------------------------------------------

def _get_existing_titles_and_topics() -> list:
    """Collect titles/topics from log and catalogs to avoid repetition."""
    existing = []
    # From dag_log
    if LOG_FILE.exists():
        try:
            log_data = json.loads(LOG_FILE.read_text(encoding="utf-8"))
            for run in log_data.get("runs", []):
                for item in run.get("items", []):
                    if item.get("title"):
                        existing.append(item["title"])
        except Exception:
            pass
    # From catalogs
    for path in [CATALOG_FILE, DRAFT_FILE]:
        if path.exists():
            try:
                data = json.loads(path.read_text(encoding="utf-8"))
                entries = data.get("scripts", []) or data.get("drafts", []) or []
                for entry in entries:
                    if entry.get("title"):
                        existing.append(entry["title"])
            except Exception:
                pass
    return existing


def _get_existing_sources() -> list:
    """Collect book/author sources already used to avoid repeating the same works."""
    sources = []
    # From catalog
    if CATALOG_FILE.exists():
        try:
            data = json.loads(CATALOG_FILE.read_text(encoding="utf-8"))
            for entry in data.get("scripts", []):
                if entry.get("source"):
                    sources.append(entry["source"])
        except Exception:
            pass
    # From draft
    if DRAFT_FILE.exists():
        try:
            data = json.loads(DRAFT_FILE.read_text(encoding="utf-8"))
            for entry in data.get("drafts", data.get("scripts", [])):
                if entry.get("source"):
                    sources.append(entry["source"])
        except Exception:
            pass
    # From dag_log
    if LOG_FILE.exists():
        try:
            log_data = json.loads(LOG_FILE.read_text(encoding="utf-8"))
            for run in log_data.get("runs", []):
                for item in run.get("items", []):
                    if item.get("source"):
                        sources.append(item["source"])
        except Exception:
            pass
    return sources


async def step_generate_ideas(count: int, fmt: str, hook_id: Optional[str] = None, extra_context: Optional[str] = None) -> list:
    """Step 1: Generate video ideas via LLM."""
    existing = _get_existing_titles_and_topics()
    existing_sources = _get_existing_sources()

    avoid_block = ""
    if existing:
        avoid_list = "\n".join(f"- {t}" for t in existing[-30:])  # last 30
        avoid_block = (
            f"\n\n–£–ñ–ï –ë–´–õ–ò –°–î–ï–õ–ê–ù–´ —ç—Ç–∏ –≤–∏–¥–µ–æ (–ù–ï –ü–û–í–¢–û–†–Ø–ô –∏—Ö –∏–¥–µ–∏, —Ç–µ–º—ã, —É–≥–ª—ã):\n"
            f"{avoid_list}\n"
            f"–ü—Ä–∏–¥—É–º–∞–π –ù–û–í–´–ï, –Ω–µ–ø–æ—Ö–æ–∂–∏–µ –∏–¥–µ–∏.\n"
        )

    # Deduplicate sources
    unique_sources = list(dict.fromkeys(s for s in existing_sources if len(s) < 200))
    if unique_sources:
        sources_list = "\n".join(f"- {s}" for s in unique_sources[-30:])
        avoid_block += (
            f"\n\n–£–ñ–ï –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ù–´–ï –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è/–∞–≤—Ç–æ—Ä—ã/–∫–Ω–∏–≥–∏ (–ù–ï –ü–û–í–¢–û–†–Ø–ô):\n"
            f"{sources_list}\n"
            f"–ò—Å–ø–æ–ª—å–∑—É–π –î–†–£–ì–ò–• –∞–≤—Ç–æ—Ä–æ–≤ –∏ –î–†–£–ì–ò–ï –∫–Ω–∏–≥–∏/–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.\n"
        )

    hook_block = ""
    if hook_id:
        hook_info = _load_hook_info(hook_id)
        if hook_info:
            hook_text = hook_info.get("hook_text", "")
            hook_mood = ", ".join(hook_info.get("mood", []))
            hook_suitable = ", ".join(hook_info.get("suitable_for", []))
            hook_block = (
                f"\n\n–í–°–ï –≤–∏–¥–µ–æ –¥–æ–ª–∂–Ω—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –û–î–ò–ù –ö–û–ù–ö–†–ï–¢–ù–´–ô —Ö—É–∫-–≤–∏–¥–µ–æ: {hook_id}\n"
                f"–¢–µ–∫—Å—Ç —Ö—É–∫–∞: ¬´{hook_text}¬ª\n"
                f"–ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ö—É–∫–∞: {hook_mood}\n"
                f"–ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Ç–µ–º: {hook_suitable}\n"
                f"–ö–∞–∂–¥–∞—è –∏–¥–µ—è –¥–æ–ª–∂–Ω–∞ –ü–û–î–•–í–ê–¢–´–í–ê–¢–¨ —Å–º—ã—Å–ª —ç—Ç–æ–≥–æ —Ö—É–∫–∞.\n"
                f"–í –ø–æ–ª–µ hook_id —É–∫–∞–∂–∏: \"{hook_id}\"\n"
            )

    # Format-specific constraints for idea generation
    fmt_constraints = {
        "micro": (
            "–§–æ—Ä–º–∞—Ç: Micro (7-15 —Å–µ–∫, 3-4 —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ú–ê–ö–°–ò–ú–£–ú).\n"
            "–û–¥–∏–Ω —Ñ–∞–∫—Ç/–∏–Ω—Å–∞–π—Ç + —ç–º–æ—Ü–∏—è. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–∏—Ä—É—Å–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª.\n"
            "–•—É–∫ = —à–æ–∫–∏—Ä—É—é—â–∞—è —Ü–∏—Ñ—Ä–∞ –∏–ª–∏ –≤–æ–ø—Ä–æ—Å. Payoff –∫ 7-–π —Å–µ–∫—É–Ω–¥–µ.\n"
            "CTA = share trigger ('–æ—Ç–ø—Ä–∞–≤—å –ø–∞—Ä—Ç–Ω—ë—Ä—É'). –ë–ï–ó Bloom CTA.\n"
        ),
        "challenge": (
            "–§–æ—Ä–º–∞—Ç: Challenge (15-20 —Å–µ–∫, 5-6 —Å—Ç—Ä–∞–Ω–∏—Ü).\n"
            "–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –∑–∞–¥–∞–Ω–∏–µ + '–ø–æ–ø—Ä–æ–±—É–π —Å–µ–≥–æ–¥–Ω—è'. Actionable, saveable.\n"
            "–•—É–∫ = –ø—Ä—è–º–∞—è –∫–æ–º–∞–Ω–¥–∞ –∏–ª–∏ –≤–æ–ø—Ä–æ—Å.\n"
            "–ó–∞–¥–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ö–û–ù–ö–†–ï–¢–ù–´–ú –∏ –≤—ã–ø–æ–ª–Ω–∏–º—ã–º —Å–µ–≥–æ–¥–Ω—è –≤–µ—á–µ—Ä–æ–º.\n"
            "CTA = '–ø–æ–ø—Ä–æ–±—É–π —Å–µ–≥–æ–¥–Ω—è –≤–µ—á–µ—Ä–æ–º' / '—Å–æ—Ö—Ä–∞–Ω–∏'.\n"
        ),
        "contrast": (
            "–§–æ—Ä–º–∞—Ç: Contrast (15-25 —Å–µ–∫, 5-7 —Å—Ç—Ä–∞–Ω–∏—Ü).\n"
            "–î–æ/–ü–æ—Å–ª–µ –ë–ï–ó –∫–Ω–∏–≥–∏ –∏ –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–∞. –ß–∏—Å—Ç–∞—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è.\n"
            "–ù–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –†–ï–ó–£–õ–¨–¢–ê–¢–ê ('–ø–æ—Å–ª–µ'), –∑–∞—Ç–µ–º —Ñ–ª–µ—à–±—ç–∫ –∫ '–¥–æ'.\n"
            "–ë–ï–ó –∫–Ω–∏–≥, –ë–ï–ó –∞–≤—Ç–æ—Ä–æ–≤, –ë–ï–ó Bloom. Engagement-only.\n"
        ),
        "debate": (
            "–§–æ—Ä–º–∞—Ç: Debate (15-25 —Å–µ–∫, 5-7 —Å—Ç—Ä–∞–Ω–∏—Ü).\n"
            "–ü—Ä–æ–≤–æ–∫–∞—Ü–∏—è + '–∞ —Ç—ã –∫–∞–∫ –¥—É–º–∞–µ—à—å?' –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏.\n"
            "–ü–æ–ª—è—Ä–∏–∑—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –∫–∞–∫ —Ö—É–∫. –î–≤–µ —Å—Ç–æ—Ä–æ–Ω—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã.\n"
            "–û—Ç–≤–µ—Ç –ù–ï –¥–∞–Ω ‚Äî –∑—Ä–∏—Ç–µ–ª—å —Ä–µ—à–∞–µ—Ç —Å–∞–º.\n"
            "CTA = '–Ω–∞–ø–∏—à–∏ –≤ –∫–æ–º–º–µ–Ω—Ç—ã'.\n"
        ),
        "story": (
            "–§–æ—Ä–º–∞—Ç: Story (20-30 —Å–µ–∫, 6-8 —Å—Ç—Ä–∞–Ω–∏—Ü).\n"
            "–°—Ç–æ—Ä–∏—Ç–µ–ª–ª–∏–Ω–≥. –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –ö–£–õ–¨–ú–ò–ù–ê–¶–ò–ò (–Ω–µ —ç–∫—Å–ø–æ–∑–∏—Ü–∏—è).\n"
            "Open loop ‚Üí –±–æ–ª—å ‚Üí –ø–æ–≤–æ—Ä–æ—Ç ‚Üí —Ä–∞–∑–≤—è–∑–∫–∞ + CTA.\n"
        ),
        "book": (
            "–§–æ—Ä–º–∞—Ç: Book (20-30 —Å–µ–∫, 6-8 —Å—Ç—Ä–∞–Ω–∏—Ü).\n"
            "–¶–∏—Ç–∞—Ç–∞ –∏–∑ –∫–Ω–∏–≥–∏ + —Ö—É–∫-–≤–∏–¥–µ–æ.\n"
            "–ò–Ω—Ç—Ä–æ –ø–æ–¥—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç —Å–º—ã—Å–ª —Ö—É–∫–∞ (–ù–ï –∏–º—è –∞–≤—Ç–æ—Ä–∞!).\n"
            "–ê–≤—Ç–æ—Ä + –∫–Ω–∏–≥–∞ + —Ü–∏—Ç–∞—Ç–∞ + –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ + CTA.\n"
        ),
        "mix": (
            "–§–æ—Ä–º–∞—Ç: –ú–∏–∫—Å ‚Äî —á–µ—Ä–µ–¥—É–π —Ñ–æ—Ä–º–∞—Ç—ã: micro, challenge, contrast, debate, story, book.\n"
            "–ö–∞–∂–¥–∞—è –∏–¥–µ—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –î–†–£–ì–û–ì–û —Ñ–æ—Ä–º–∞—Ç–∞. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ.\n"
        ),
    }

    fmt_block = fmt_constraints.get(fmt, fmt_constraints["story"])

    prompt = (
        f"–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π {count} –∏–¥–µ–π –¥–ª—è –≤–∏–¥–µ–æ Bloom (–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –æ—Ç–Ω–æ—à–µ–Ω–∏–π).\n"
        f"{fmt_block}\n"
        f"–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û ‚Äî –•–£–ö (–ø–µ—Ä–≤–∞—è —Ñ—Ä–∞–∑–∞ –≤–∏–¥–µ–æ):\n"
        f"–•—É–∫ –¥–æ–ª–∂–µ–Ω –û–°–¢–ê–ù–û–í–ò–¢–¨ —Å–∫—Ä–æ–ª–ª –∑–∞ 1 —Å–µ–∫—É–Ω–¥—É. –ü—Ä–∞–≤–∏–ª–∞:\n"
        f"‚Ä¢ –ú–∞–∫—Å–∏–º—É–º 6-8 —Å–ª–æ–≤. –ö–æ—Ä–æ—á–µ = –ª—É—á—à–µ.\n"
        f"‚Ä¢ –û—Ç –ø–µ—Ä–≤–æ–≥–æ –ª–∏—Ü–∞: ¬´–Ø¬ª, ¬´–ú–æ–π¬ª, ¬´–ú—ã¬ª ‚Äî –ù–ï ¬´–õ—é–¥–∏¬ª, ¬´–ú–Ω–æ–≥–∏–µ¬ª.\n"
        f"‚Ä¢ –ö–æ–Ω–∫—Ä–µ—Ç–∏–∫–∞: –∏–º–µ–Ω–∞, —á–∏—Å–ª–∞, –¥–µ—Ç–∞–ª–∏ ‚Äî –ù–ï –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏.\n"
        f"‚Ä¢ –û—Ç–∫—Ä—ã—Ç–∞—è –ø–µ—Ç–ª—è: –∑—Ä–∏—Ç–µ–ª—å –î–û–õ–ñ–ï–ù —É–∑–Ω–∞—Ç—å —á—Ç–æ –¥–∞–ª—å—à–µ.\n"
        f"‚Ä¢ –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç—Ä–∏–≥–≥–µ—Ä: –±–æ–ª—å, —à–æ–∫, –∑–∞–≤–∏—Å—Ç—å, —Å—Ç—Ä–∞—Ö, –ª—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ.\n\n"
        f"5 —Ñ–æ—Ä–º—É–ª —Ö—É–∫–æ–≤ (—á–µ—Ä–µ–¥—É–π!):\n"
        f"1. –í–´–ï–ë–û–ù–´ (—Ç—Ä–∏–≥–≥–µ—Ä —Å—Ç–∞—Ç—É—Å–∞): ¬´–ú–æ–π –ø–∞—Ä–µ–Ω—å –¥–µ–ª–∞–µ—Ç –º–Ω–µ —Å—é—Ä–ø—Ä–∏–∑ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å¬ª\n"
        f"2. –í–û–õ–®–ï–ë–ù–ê–Ø –¢–ê–ë–õ–ï–¢–ö–ê (1 –¥–µ–π—Å—Ç–≤–∏–µ ‚Üí —Ä–µ–∑—É–ª—å—Ç–∞—Ç): ¬´–û–¥–Ω–∞ —Ñ—Ä–∞–∑–∞ —Å–ø–∞—Å–ª–∞ –Ω–∞—à –±—Ä–∞–∫¬ª\n"
        f"3. –ó–ê–ü–†–ï–¢–ù–´–ô –ü–õ–û–î (—Å–∫—Ä—ã—Ç–∞—è –ø—Ä–∞–≤–¥–∞): ¬´–ü—Å–∏—Ö–æ–ª–æ–≥–∏ —ç—Ç–æ —Å–∫—Ä—ã–≤–∞—é—Ç, –Ω–æ 80% –ø–∞—Ä...¬ª\n"
        f"4. –ö–û–ù–¢–†–ê–°–¢ (–¥–æ/–ø–æ—Å–ª–µ): ¬´–ì–æ–¥ –Ω–∞–∑–∞–¥ –º—ã –Ω–µ —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞–ª–∏. –°–µ–π—á–∞—Å –Ω–µ –º–æ–∂–µ–º –∑–∞–º–æ–ª—á–∞—Ç—å¬ª\n"
        f"5. –°–¢–†–ê–•/FOMO: ¬´–ï—Å–ª–∏ —Ç—ã –Ω–µ –¥–µ–ª–∞–µ—à—å —ç—Ç–æ ‚Äî —Ç–≤–æ–∏ –æ—Ç–Ω–æ—à–µ–Ω–∏—è —É–º–∏—Ä–∞—é—Ç¬ª\n\n"
        f"–ü–õ–û–•–ò–ï —Ö—É–∫–∏ (–ù–ï –î–ï–õ–ê–ô –¢–ê–ö):\n"
        f"‚Ä¢ ¬´–û—Ç–Ω–æ—à–µ–Ω–∏—è ‚Äî —ç—Ç–æ –≤–∞–∂–Ω–æ¬ª ‚Äî —Å–∫—É—á–Ω–æ, –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω–æ\n"
        f"‚Ä¢ ¬´–ú–Ω–æ–≥–∏–µ –ø–∞—Ä—ã —Å—Ç–∞–ª–∫–∏–≤–∞—é—Ç—Å—è —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏¬ª ‚Äî –±–∞–Ω–∞–ª—å–Ω–æ\n"
        f"‚Ä¢ ¬´–ö–∞–∫ —É–ª—É—á—à–∏—Ç—å –æ—Ç–Ω–æ—à–µ–Ω–∏—è¬ª ‚Äî –∑–≤—É—á–∏—Ç –∫–∞–∫ –ª–µ–∫—Ü–∏—è\n\n"
        f"–ö–∞–∂–¥–∞—è –∏–¥–µ—è: title, concept, hook_type (status_trigger/magic_pill/"
        f"forbidden_fruit/contrast/fomo), hook_text (–¢–û–ß–ù–´–ô —Ç–µ–∫—Å—Ç —Ö—É–∫–∞ ‚Äî 6-8 —Å–ª–æ–≤), mood, tags.\n"
        f"–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ: —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º—É–ª—ã —Ö—É–∫–æ–≤, —Ä–∞–∑–Ω—ã–µ —ç–º–æ—Ü–∏–∏, —Ä–∞–∑–Ω—ã–µ –±–æ–ª–∏.\n"
        f"–í–µ—Ä–Ω–∏ JSON –º–∞—Å—Å–∏–≤ –∏–∑ {count} –æ–±—ä–µ–∫—Ç–æ–≤."
        f"{hook_block}"
        f"{avoid_block}"
    )

    if extra_context:
        prompt += (
            f"\n\n–ê–ù–ê–õ–ò–¢–ò–ö–ê –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–ò (–∏—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏—è):\n"
            f"{extra_context}\n"
            f"–ì–µ–Ω–µ—Ä–∏—Ä—É–π –∏–¥–µ–∏, –≤–¥–æ—Ö–Ω–æ–≤–ª—ë–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω—ã–º–∏ —Ç–µ–º–∞–º–∏ –∏ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏ –∏–∑ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏.\n"
        )

    ideas = await chat_json(prompt, scope="ideas", timeout=180)
    if isinstance(ideas, dict):
        ideas = [ideas]
    return ideas[:count]


def _format_duration(fmt: str) -> str:
    """Return target duration string for a given format."""
    return {
        "micro": "7-15 —Å–µ–∫—É–Ω–¥ (max 15!)",
        "challenge": "15-20 —Å–µ–∫—É–Ω–¥",
        "contrast": "15-25 —Å–µ–∫—É–Ω–¥",
        "debate": "15-25 —Å–µ–∫—É–Ω–¥",
        "story": "20-30 —Å–µ–∫—É–Ω–¥",
        "book": "20-30 —Å–µ–∫—É–Ω–¥",
    }.get(fmt, "20-30 —Å–µ–∫—É–Ω–¥")


async def step_generate_script(item: DagItem, on_progress: Optional[Callable] = None, hook_id: Optional[str] = None, extra_context: Optional[str] = None) -> None:
    """Step 2: Generate full script from idea via LLM."""
    item.status = "script"
    item.timings["script_start"] = _now()
    if on_progress:
        await on_progress(item.id, "script", f"üìù –ü–∏—à—É —Å—Ü–µ–Ω–∞—Ä–∏–π: {item.title}")

    hook_context = ""
    if hook_id:
        hook_info = _load_hook_info(hook_id)
        if hook_info:
            hook_context = (
                f"\n\n–í–∏–¥–µ–æ –Ω–∞—á–Ω—ë—Ç—Å—è —Å —Ö—É–∫-–≤–∏–¥–µ–æ (id: {hook_id}).\n"
                f"–¢–µ–∫—Å—Ç —Ö—É–∫–∞: ¬´{hook_info.get('hook_text', '')}¬ª\n"
                f"Intro (Page 1 —Å–∫—Ä–∏–ø—Ç–∞) –¥–æ–ª–∂–µ–Ω –ø–æ–¥—Ö–≤–∞—Ç—ã–≤–∞—Ç—å —Å–º—ã—Å–ª —ç—Ç–æ–≥–æ —Ö—É–∫–∞.\n"
                f"–í –ø–æ–ª–µ hook_id —É–∫–∞–∂–∏: \"{hook_id}\"\n"
            )

    fmt = item.format or "story"

    # Format-specific script structure instructions
    _fmt_instructions = {
        "micro": (
            "\n\n–§–û–†–ú–ê–¢: Micro (7-15 —Å–µ–∫, 3-4 —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ú–ê–ö–°–ò–ú–£–ú)\n"
            "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ script_text:\n"
            "Page 1 (–•–£–ö): –ú–ê–ö–°–ò–ú–£–ú 5-8 —Å–ª–æ–≤! –®–æ–∫–∏—Ä—É—é—â–∞—è —Ü–∏—Ñ—Ä–∞ –∏–ª–∏ –≤–æ–ø—Ä–æ—Å.\n"
            "Page 2-3: –û–¥–∏–Ω —Ñ–∞–∫—Ç/–∏–Ω—Å–∞–π—Ç + —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —É–¥–∞—Ä.\n"
            "Page 3-4 (CTA): Share trigger ‚Äî '–æ—Ç–ø—Ä–∞–≤—å –ø–∞—Ä—Ç–Ω—ë—Ä—É', '—Å–æ—Ö—Ä–∞–Ω–∏'.\n"
            "–ó–ê–ü–†–ï–¢: –ù–ï —É–ø–æ–º–∏–Ω–∞–π Bloom. –¢–æ–ª—å–∫–æ engagement CTA.\n"
        ),
        "challenge": (
            "\n\n–§–û–†–ú–ê–¢: Challenge (15-20 —Å–µ–∫, 5-6 —Å—Ç—Ä–∞–Ω–∏—Ü)\n"
            "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ script_text:\n"
            "Page 1 (–•–£–ö): –ü—Ä—è–º–∞—è –∫–æ–º–∞–Ω–¥–∞ –∏–ª–∏ –≤–æ–ø—Ä–æ—Å. 5-8 —Å–ª–æ–≤.\n"
            "Pages 2-3: –ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ. –ë–æ–ª—å/–ø—Ä–æ–±–ª–µ–º–∞.\n"
            "Pages 4-5: –ö–û–ù–ö–†–ï–¢–ù–û–ï –∑–∞–¥–∞–Ω–∏–µ ‚Äî –≤—ã–ø–æ–ª–Ω–∏–º–æ —Å–µ–≥–æ–¥–Ω—è –≤–µ—á–µ—Ä–æ–º.\n"
            "Page 6 (CTA): '–ü–æ–ø—Ä–æ–±—É–π —Å–µ–≥–æ–¥–Ω—è –≤–µ—á–µ—Ä–æ–º' / '–°–æ—Ö—Ä–∞–Ω–∏ –∏ –ø–æ–ø—Ä–æ–±—É–π'.\n"
        ),
        "contrast": (
            "\n\n–§–û–†–ú–ê–¢: Contrast (15-25 —Å–µ–∫, 5-7 —Å—Ç—Ä–∞–Ω–∏—Ü)\n"
            "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ script_text:\n"
            "Page 1 (–•–£–ö): –†–ï–ó–£–õ–¨–¢–ê–¢ ('–ø–æ—Å–ª–µ'). 5-8 —Å–ª–æ–≤. –ö–æ–Ω—Ç—Ä–∞—Å—Ç.\n"
            "Pages 2-3: –§–ª–µ—à–±—ç–∫ –∫ '–¥–æ'. –ë–æ–ª—å, –¥–µ—Ç–∞–ª–∏, –∏–º–µ–Ω–∞.\n"
            "Pages 4-5: –ü–æ–≤–æ—Ä–æ—Ç–Ω—ã–π –º–æ–º–µ–Ω—Ç. –ß—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å.\n"
            "Pages 6-7: –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ä–∞–∑–≤—è–∑–∫–∞ + CTA (engagement-only).\n"
            "–ó–ê–ü–†–ï–¢: –ë–ï–ó –∫–Ω–∏–≥, –ë–ï–ó –∞–≤—Ç–æ—Ä–æ–≤, –ë–ï–ó Bloom.\n"
        ),
        "debate": (
            "\n\n–§–û–†–ú–ê–¢: Debate (15-25 —Å–µ–∫, 5-7 —Å—Ç—Ä–∞–Ω–∏—Ü)\n"
            "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ script_text:\n"
            "Page 1 (–•–£–ö): –ü–æ–ª—è—Ä–∏–∑—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å. 5-8 —Å–ª–æ–≤.\n"
            "Pages 2-3: –°—Ç–æ—Ä–æ–Ω–∞ 1 ‚Äî –∞—Ä–≥—É–º–µ–Ω—Ç –ó–ê.\n"
            "Pages 4-5: –°—Ç–æ—Ä–æ–Ω–∞ 2 ‚Äî –∞—Ä–≥—É–º–µ–Ω—Ç –ü–†–û–¢–ò–í.\n"
            "Pages 6-7: –ù–ï –¥–∞–≤–∞–π –æ—Ç–≤–µ—Ç. '–ê —Ç—ã –∫–∞–∫ –¥—É–º–∞–µ—à—å?' + CTA '–Ω–∞–ø–∏—à–∏ –≤ –∫–æ–º–º–µ–Ω—Ç—ã'.\n"
        ),
        "story": (
            "\n\n–§–û–†–ú–ê–¢: Story (20-30 —Å–µ–∫, 6-8 —Å—Ç—Ä–∞–Ω–∏—Ü)\n"
            "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ script_text:\n"
            "Page 1 (–•–£–ö): –ú–ê–ö–°–ò–ú–£–ú 5-8 —Å–ª–æ–≤! –ö–æ—Ä–æ—Ç–∫–∞—è —Ñ—Ä–∞–∑–∞, –±—å—ë—Ç –≤ –ª–æ–±.\n"
            "  –ü—Ä–∏–º–µ—Ä: **–û–Ω–∞** —Å–∫–∞–∑–∞–ª–∞ *¬´—É—Ö–æ–¥–∏¬ª* ‚Äî –∏ —è **—É—à—ë–ª**\n"
            "  –ü—Ä–∏–º–µ—Ä: **–û–¥–Ω–∞** –ø—Ä–∏–≤—ã—á–∫–∞. –ù–∞—à *–±—Ä–∞–∫* ‚Äî **—Å–ø–∞—Å—ë–Ω.**\n"
            "Pages 2-3 (setup): –°–∏—Ç—É–∞—Ü–∏—è. –î–µ—Ç–∞–ª–∏. –ò–º–µ–Ω–∞. 2-3 —Å—Ç—Ä–æ–∫–∏.\n"
            "Pages 4-6 (story): –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è —Å –ø–æ–≤–æ—Ä–æ—Ç–∞–º–∏.\n"
            "  –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ—Ç–∞–ª–∏: –¥–∏–∞–ª–æ–≥–∏ –≤ [c:lime]¬´–∫–∞–≤—ã—á–∫–∞—Ö¬ª[/], –∏–º–µ–Ω–∞, –º–µ—Å—Ç–∞.\n"
            "Pages 7-8 (CTA): –ü–æ–≤–æ—Ä–æ—Ç + CTA (engagement –∏–ª–∏ Bloom).\n"
        ),
        "book": (
            "\n\n–§–û–†–ú–ê–¢: Book (20-30 —Å–µ–∫, 6-8 —Å—Ç—Ä–∞–Ω–∏—Ü + —Ö—É–∫-–≤–∏–¥–µ–æ)\n"
            "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ script_text:\n"
            "Page 1 (intro): –ü–æ–¥—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç —Å–º—ã—Å–ª —Ö—É–∫–∞. 1-2 —Å—Ç—Ä–æ–∫–∏.\n"
            "Page 2: [img:–æ–±–ª–æ–∂–∫–∞.jpg] + –∞–≤—Ç–æ—Ä + –∫–Ω–∏–≥–∞\n"
            "Page 3: –¶–∏—Ç–∞—Ç–∞ [c:gold]¬´—Ç–µ–∫—Å—Ç¬ª[/]\n"
            "Pages 4-6: –†–∞–∑–≤–∏—Ç–∏–µ –º—ã—Å–ª–∏, –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ —Å–∏—Ç—É–∞—Ü–∏–∏\n"
            "Pages 7-8: –†–µ—à–µ–Ω–∏–µ + CTA.\n"
        ),
    }

    fmt_instructions = _fmt_instructions.get(fmt, _fmt_instructions["story"])

    prompt = (
        f"–ù–∞–ø–∏—à–∏ —Å—Ü–µ–Ω–∞—Ä–∏–π –ø–æ —ç—Ç–æ–π –∏–¥–µ–µ:\n"
        f"{json.dumps(item.idea, ensure_ascii=False, indent=2)}\n"
        f"{fmt_instructions}\n"
        f"–£–î–ï–†–ñ–ê–ù–ò–ï ‚Äî –ì–õ–ê–í–ù–´–ô –ü–†–ò–û–†–ò–¢–ï–¢:\n"
        f"‚Ä¢ Page 1 = –•–£–ö. –ú–∞–∫—Å–∏–º—É–º 5-8 —Å–ª–æ–≤. –û–¥–Ω–∞ –º—ã—Å–ª—å. –®–æ–∫, –±–æ–ª—å, –∏–Ω—Ç—Ä–∏–≥–∞.\n"
        f"‚Ä¢ –ö–∞–∂–¥–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –æ—Ç–∫—Ä—ã—Ç–æ–π –ø–µ—Ç–ª—ë–π ‚Äî –∑—Ä–∏—Ç–µ–ª—å –û–ë–Ø–ó–ê–ù –ª–∏—Å—Ç–∞—Ç—å –¥–∞–ª—å—à–µ.\n"
        f"‚Ä¢ –ù–∏–∫–∞–∫–∏—Ö –¥–ª–∏–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –ö–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî —É–¥–∞—Ä.\n"
        f"‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π styled markup: **–∞–∫—Ü–µ–Ω—Ç**, *–≤—ã–¥–µ–ª–µ–Ω–∏–µ*, _–ø—Ä–∏–≥–ª—É—à—ë–Ω–Ω–æ–µ_,\n"
        f"  [c:color]—Ü–≤–µ—Ç[/], [img:file.jpg], --- (—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Å—Ç—Ä–∞–Ω–∏—Ü).\n"
        f"‚Ä¢ plain_text ‚Äî —Ç–æ—Ç –∂–µ —Ç–µ–∫—Å—Ç –±–µ–∑ markup (–¥–ª—è TTS).\n"
        f"‚Ä¢ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {_format_duration(fmt)}. –ù–ï —Ä–∞—Å—Ç—è–≥–∏–≤–∞–π!\n\n"
        f"–í–µ—Ä–Ω–∏ JSON —Å –ø–æ–ª—è–º–∏: format, title, hook_id, hook_type, mood, tags, voice, "
        f"duration_target, source, image, script_text, plain_text, instagram_caption."
        f"{hook_context}"
    )

    if extra_context:
        prompt += (
            f"\n\n–ê–ù–ê–õ–ò–¢–ò–ö–ê –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–ò (—É—á–∏—Ç—ã–≤–∞–π –ø—Ä–∏ –Ω–∞–ø–∏—Å–∞–Ω–∏–∏ —Å—Ü–µ–Ω–∞—Ä–∏—è):\n"
            f"{extra_context}\n"
            f"–û—Ä–∏–µ–Ω—Ç–∏—Ä—É–π—Å—è –Ω–∞ —Å—Ç–∏–ª—å –∏ —Ç–µ–º—ã —É—Å–ø–µ—à–Ω—ã—Ö —Å–∫—Ä–∏–ø—Ç–æ–≤ –∏–∑ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏.\n"
        )

    script = await chat_json(prompt, scope="scripts", timeout=180)
    item.script = script
    item.title = script.get("title", item.title)
    item.plain_text = script.get("plain_text", "")
    item.instagram_caption = script.get("instagram_caption", "")
    item.format = script.get("format", item.format)
    item.hook_type = script.get("hook_type", item.hook_type)
    # If specific hook was selected, ensure hook_id is set in the script
    if hook_id:
        item.script["hook_id"] = hook_id
    item.timings["script_done"] = _now()


async def step_inject_tts_tags(item: DagItem, on_progress: Optional[Callable] = None) -> None:
    """Step 2.5: Inject ElevenLabs v3 audio tags into plain text for expressive TTS."""
    if on_progress:
        await on_progress(item.id, "tts_tags", f"üé≠ –î–æ–±–∞–≤–ª—è—é —ç–º–æ—Ü–∏–∏: {item.title}")

    if not item.plain_text:
        return

    fmt = item.format or "story"
    mood = (item.script or {}).get("mood", "")
    hook_type = item.hook_type or ""

    prompt = (
        f"–î–æ–±–∞–≤—å ElevenLabs v3 audio tags –≤ —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏.\n\n"
        f"–¢–ï–ö–°–¢:\n{item.plain_text}\n\n"
        f"–ö–û–ù–¢–ï–ö–°–¢: —Ñ–æ—Ä–º–∞—Ç={fmt}, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ={mood}, —Ç–∏–ø —Ö—É–∫–∞={hook_type}\n\n"
        f"–ü–†–ê–í–ò–õ–ê:\n"
        f"1. –ù–ï –ú–ï–ù–Ø–ô —Å–ª–æ–≤–∞ ‚Äî —Ç–æ–ª—å–∫–æ –¥–æ–±–∞–≤–ª—è–π —Ç–µ–≥–∏ –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö.\n"
        f"2. –ù–ï —É–¥–∞–ª—è–π –∏ –ù–ï –ø–µ—Ä–µ—Å—Ç–∞–≤–ª—è–π —Å–ª–æ–≤–∞.\n"
        f"3. –¢–µ–≥–∏ —Å—Ç–∞–≤—è—Ç—Å—è –ü–ï–†–ï–î —Ñ—Ä–∞–∑–æ–π, –Ω–∞ –∫–æ—Ç–æ—Ä—É—é –≤–ª–∏—è—é—Ç.\n"
        f"4. –ò—Å–ø–æ–ª—å–∑—É–π –†–ê–ó–ù–û–û–ë–†–ê–ó–ù–´–ï —Ç–µ–≥–∏, –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–π –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ.\n"
        f"5. –°–ª–µ–¥—É–π —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –∞—Ä–∫–µ —Ç–µ–∫—Å—Ç–∞.\n\n"
        f"–î–û–°–¢–£–ü–ù–´–ï –¢–ï–ì–ò:\n"
        f"–≠–º–æ—Ü–∏–∏: [sad] [happy] [angry] [excited] [nervous] [sarcastic] [curious] [wistful]\n"
        f"–ü–æ–¥–∞—á–∞: [whispers] [shouts] [softly] [gently] [calm] [dramatic]\n"
        f"–†–µ–∞–∫—Ü–∏–∏: [laughs] [sighs] [gasps] [sniffles] [breathes] [clears throat]\n"
        f"–¢–µ–º–ø: [pause] [hesitates] [rushed] [slows down] [deliberate]\n"
        f"–°—Ç–∏–ª—å: [dramatic tone] [matter-of-fact] [reflective] [serious tone]\n\n"
        f"–ü–ê–¢–¢–ï–†–ù –î–õ–Ø –í–ò–î–ï–û:\n"
        f"‚Ä¢ –•—É–∫ (–Ω–∞—á–∞–ª–æ): [dramatic] –∏–ª–∏ [whispers] –∏–ª–∏ [serious tone] ‚Äî –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n"
        f"‚Ä¢ –ë–æ–ª—å/–ø—Ä–æ–±–ª–µ–º–∞: [sad] [softly] [pause]\n"
        f"‚Ä¢ –ü–æ–≤–æ—Ä–æ—Ç: [pause] [excited] –∏–ª–∏ [gasps]\n"
        f"‚Ä¢ –†–∞–∑–≤—è–∑–∫–∞/CTA: [calm] [gently] –∏–ª–∏ [happy]\n\n"
        f"–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç —Å —Ç–µ–≥–∞–º–∏, –±–µ–∑ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π, –±–µ–∑ –∫–∞–≤—ã—á–µ–∫, –±–µ–∑ markdown."
    )

    try:
        from llm_client import chat
        result = await chat(prompt, scope="general", timeout=90)
        result = result.strip()
        # Sanity check: result should contain at least one tag and roughly the same words
        if "[" in result and len(result) > len(item.plain_text) * 0.5:
            item.tts_text = result
            logger.info(f"TTS tags injected for #{item.id}: {len(result)} chars (was {len(item.plain_text)})")
        else:
            logger.warning(f"TTS tag injection returned suspicious result for #{item.id}, using plain text")
            item.tts_text = item.plain_text
    except Exception as e:
        logger.warning(f"TTS tag injection failed for #{item.id}, using plain text: {e}")
        item.tts_text = item.plain_text


async def step_generate_tts(item: DagItem, on_progress: Optional[Callable] = None) -> None:
    """Step 3: Generate TTS audio via kie_tts.py."""
    item.status = "tts"
    item.timings["tts_start"] = _now()
    if on_progress:
        await on_progress(item.id, "tts", f"üéô –û–∑–≤—É—á–∏–≤–∞—é: {item.title}")

    audio_path = str(DOWNLOADS_DIR / f"bloom_{item.id}_audio.mp3")

    # Write plain text to temp file (handles long texts)
    txt_path = str(DOWNLOADS_DIR / f"bloom_{item.id}_tts_input.txt")
    Path(txt_path).write_text(item.plain_text, encoding="utf-8")

    cmd = [
        sys.executable, str(SCRIPTS_DIR / "kie_tts.py"),
        txt_path,
        "-v", item.script.get("voice", "EiNlNiXeDU1pqqOPrYMO"),
        "-o", audio_path,
    ]
    proc = await asyncio.create_subprocess_exec(
        *cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE
    )
    stdout, stderr = await proc.communicate()
    if proc.returncode != 0:
        raise RuntimeError(f"TTS failed: {stderr.decode()}")

    item.files["audio"] = audio_path
    # Clean up temp file
    Path(txt_path).unlink(missing_ok=True)
    item.timings["tts_done"] = _now()


AUDIO_SPEED = 1.1  # Final audio speed multiplier


async def step_speedup_audio(item: DagItem, on_progress: Optional[Callable] = None) -> None:
    """Step 3.5: Speed up TTS audio by AUDIO_SPEED factor."""
    import imageio_ffmpeg
    ffmpeg = imageio_ffmpeg.get_ffmpeg_exe()

    src = item.files["audio"]
    dst = src.replace("_audio.mp3", "_audio_fast.mp3")

    cmd = [
        ffmpeg, "-y", "-i", src,
        "-filter:a", f"atempo={AUDIO_SPEED}",
        "-vn", dst,
    ]
    proc = await asyncio.create_subprocess_exec(
        *cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE
    )
    _, stderr = await proc.communicate()
    if proc.returncode != 0:
        logger.warning(f"Audio speedup failed for #{item.id}, using original: {stderr.decode()[-200:]}")
        return

    # Replace original with sped-up version
    Path(src).unlink(missing_ok=True)
    Path(dst).rename(src)
    logger.info(f"Audio #{item.id} sped up to {AUDIO_SPEED}x")


async def step_extract_timestamps(item: DagItem, on_progress: Optional[Callable] = None) -> None:
    """Step 4: Extract word timestamps via Whisper."""
    item.status = "timestamps"
    item.timings["ts_start"] = _now()
    if on_progress:
        await on_progress(item.id, "timestamps", f"‚è± –¢–∞–π–º—Å—Ç–∞–º–ø—ã: {item.title}")

    ts_path = str(DOWNLOADS_DIR / f"bloom_{item.id}_timestamps.json")
    cmd = [
        sys.executable, str(SCRIPTS_DIR / "audio_to_word_timestamps.py"),
        item.files["audio"],
        "-o", ts_path,
        "--speed", "1.0",  # audio already sped up, no additional speedup
    ]
    proc = await asyncio.create_subprocess_exec(
        *cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE
    )
    stdout, stderr = await proc.communicate()
    if proc.returncode != 0:
        raise RuntimeError(f"Timestamps failed: {stderr.decode()}")

    item.files["timestamps"] = ts_path
    item.timings["ts_done"] = _now()


async def step_write_markup(item: DagItem, on_progress: Optional[Callable] = None) -> None:
    """Step 5: Write markup file from script_text."""
    item.status = "markup"
    markup_path = str(DOWNLOADS_DIR / f"bloom_{item.id}_markup.txt")
    script_text = item.script.get("script_text", "")
    Path(markup_path).write_text(script_text, encoding="utf-8")
    item.files["markup"] = markup_path


async def step_select_backgrounds(item: DagItem, on_progress: Optional[Callable] = None) -> None:
    """Step 5.5: Use LLM to select relevant backgrounds per page."""
    item.timings["bg_start"] = _now()
    if on_progress:
        await on_progress(item.id, "backgrounds", f"üé® –ü–æ–¥–±–∏—Ä–∞—é —Ñ–æ–Ω—ã: {item.title}")

    # Read background catalog
    if not BG_CATALOG.exists():
        return  # No catalog ‚Äî renderer will use default round-robin

    bg_catalog = json.loads(BG_CATALOG.read_text(encoding="utf-8"))
    videos = bg_catalog.get("videos", [])
    if not videos:
        return

    # Build compact catalog summary for LLM
    bg_summary = []
    for v in videos:
        bg_summary.append({
            "filename": v["filename"],
            "mood": v.get("semantic", {}).get("mood", []),
            "themes": v.get("semantic", {}).get("themes", []),
            "style": v.get("semantic", {}).get("style", ""),
            "keywords_ru": v.get("keywords_ru", []),
            "brightness": v.get("visual", {}).get("brightness", ""),
        })

    # Count pages in script
    script_text = item.script.get("script_text", "")
    pages = [p.strip() for p in script_text.split("---") if p.strip()]
    page_count = len(pages)

    # Build compact page descriptions
    page_descriptions = []
    for i, page in enumerate(pages):
        # Strip markup tags for cleaner description
        clean = page.replace("[/]", "")
        clean = re.sub(r"\[(?:c|s|img):[^\]]*\]", "", clean)
        clean = clean.replace("**", "").replace("*", "").replace("_", "")
        clean = clean.strip()[:100]
        page_descriptions.append(f"Page {i+1}: {clean}")

    prompt = (
        f"–£ –º–µ–Ω—è {page_count} —Å—Ç—Ä–∞–Ω–∏—Ü –≤–∏–¥–µ–æ-—Å–∫—Ä–∏–ø—Ç–∞. –ü–æ–¥–±–µ—Ä–∏ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã "
        f"–Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Ñ–æ–Ω –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞.\n\n"
        f"–°—Ç—Ä–∞–Ω–∏—Ü—ã:\n" + "\n".join(page_descriptions) + "\n\n"
        f"–ö–∞—Ç–∞–ª–æ–≥ —Ñ–æ–Ω–æ–≤:\n{json.dumps(bg_summary, ensure_ascii=False)}\n\n"
        f"–í–µ—Ä–Ω–∏ JSON –º–∞—Å—Å–∏–≤ –∏–∑ {page_count} —Å—Ç—Ä–æ–∫ ‚Äî filename —Ñ–æ–Ω–∞ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ –ø–æ—Ä—è–¥–∫—É.\n"
        f"–ü—Ä–∏–º–µ—Ä: [\"file1.mp4\", \"file2.mp4\", \"file1.mp4\"]\n"
        f"–í—ã–±–∏—Ä–∞–π —Ñ–æ–Ω—ã –ø–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—é –∏ —Ç–µ–º–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã. –ú–æ–∂–Ω–æ –ø–æ–≤—Ç–æ—Ä—è—Ç—å."
    )

    try:
        bg_selection = await chat_json(prompt, scope="general", timeout=120)
        if isinstance(bg_selection, list) and len(bg_selection) >= page_count:
            # Create temp directory with copies in the right order + catalog.json
            temp_bg_dir = Path(tempfile.mkdtemp(prefix="bloom_bg_"))
            catalog_videos = []

            for i, bg_file in enumerate(bg_selection[:page_count]):
                src = BG_DIR / bg_file
                if src.exists():
                    dst_name = f"{i:03d}_{bg_file}"
                    dst = temp_bg_dir / dst_name
                    shutil.copy2(str(src), str(dst))
                    # Find original catalog entry for metadata
                    orig = next((v for v in videos if v["filename"] == bg_file), {})
                    catalog_videos.append({
                        "filename": dst_name,
                        "path": str(dst),
                        "technical": orig.get("technical", {}),
                        "visual": orig.get("visual", {}),
                        "semantic": orig.get("semantic", {}),
                    })

            # Write catalog.json so styled_subtitles.py can find backgrounds
            catalog_data = {"version": "1.0", "videos": catalog_videos}
            (temp_bg_dir / "catalog.json").write_text(
                json.dumps(catalog_data, ensure_ascii=False, indent=2), encoding="utf-8"
            )

            item.files["bg_dir"] = str(temp_bg_dir)
            item.timings["bg_done"] = _now()
            return
    except Exception as e:
        logger.warning(f"Background selection failed for #{item.id}, using default: {e}")

    item.timings["bg_done"] = _now()


async def step_render_video(item: DagItem, on_progress: Optional[Callable] = None,
                            cta_always: bool = True, countdown_path: Optional[str] = None) -> None:
    """Step 6: Render video via styled_subtitles.py. Optionally prepend countdown."""
    item.status = "rendering"
    item.timings["render_start"] = _now()
    if on_progress:
        await on_progress(item.id, "rendering", f"üé¨ –†–µ–Ω–¥–µ—Ä—é: {item.title}")

    video_path = str(OUTPUT_DIR / f"bloom_{item.id}_final.mp4")
    # If countdown, render main content to temp file first
    main_path = video_path if not countdown_path else str(OUTPUT_DIR / f"bloom_{item.id}_main.mp4")

    # Use LLM-selected backgrounds if available, otherwise default catalog
    bg_dir = item.files.get("bg_dir") or str(BG_DIR)

    cmd = [
        sys.executable, str(SCRIPTS_DIR / "styled_subtitles.py"),
        item.files["markup"],
        item.files["audio"],
        item.files["timestamps"],
        "--bg-dir", bg_dir,
        "--threads", "20",
        "--progress-bar",
        "-o", main_path,
    ]

    # CTA display mode
    if not cta_always:
        cmd.append("--no-cta-always")

    # Add background music if available
    music_files = list(MUSIC_DIR.glob("*.mp3")) if MUSIC_DIR.exists() else []
    if music_files:
        music_file = random.choice(music_files)
        cmd.extend(["--music", str(music_file), "--music-volume", "0.12"])

    # Add hook if specified in script (from bank or LLM) ‚Äî skip if countdown mode
    if not countdown_path:
        script_hook_id = item.script.get("hook_id") if item.script else None
        if script_hook_id:
            hook_path = HOOKS_DIR / f"{script_hook_id}.mp4"
            if hook_path.exists():
                cmd.extend(["--hook", str(hook_path), "--hook-intro"])

    proc = await asyncio.create_subprocess_exec(
        *cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE,
        cwd=str(PROJECT_ROOT),
    )
    stdout, stderr = await proc.communicate()
    if proc.returncode != 0:
        raise RuntimeError(f"Render failed: {stderr.decode()[-500:]}")

    # Prepend countdown if requested
    if countdown_path and os.path.exists(countdown_path):
        if on_progress:
            await on_progress(item.id, "rendering", f"‚è± –î–æ–±–∞–≤–ª—è—é —Ç–∞–π–º–µ—Ä: {item.title}")
        await _prepend_countdown(countdown_path, main_path, video_path)
        try:
            os.remove(main_path)
        except OSError:
            pass

    item.files["video"] = video_path
    item.timings["render_done"] = _now()


async def _prepend_countdown(countdown_path: str, main_path: str, output_path: str) -> None:
    """Concatenate countdown video + main video using ffmpeg concat demuxer."""
    from styled_subtitles import get_ffmpeg_path
    ffmpeg = get_ffmpeg_path()

    concat_list = output_path + ".concat.txt"
    with open(concat_list, "w", encoding="utf-8") as f:
        f.write(f"file '{countdown_path.replace(os.sep, '/')}'\n")
        f.write(f"file '{main_path.replace(os.sep, '/')}'\n")

    # Always re-encode to avoid freeze at concat boundary
    cmd = [
        ffmpeg, "-y", "-f", "concat", "-safe", "0", "-i", concat_list,
        "-c:v", "libx264", "-preset", "fast", "-crf", "20",
        "-c:a", "aac", "-b:a", "192k",
        "-r", "30",
        output_path,
    ]
    proc = await asyncio.create_subprocess_exec(
        *cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE,
    )
    _, stderr = await proc.communicate()
    if proc.returncode != 0:
        raise RuntimeError(f"Countdown concat failed: {stderr.decode()[-300:]}")

    try:
        os.remove(concat_list)
    except OSError:
        pass


async def step_log_result(item: DagItem, run: DagRun) -> None:
    """Step 7: Log result to JSON."""
    item.status = "done"
    item.timings["done_at"] = _now()

    # Update scripts catalog
    _update_catalog(item)


# ---------------------------------------------------------------------------
# Pipeline
# ---------------------------------------------------------------------------

async def process_item(
    item: DagItem,
    run: DagRun,
    sem: asyncio.Semaphore,
    on_progress: Optional[Callable] = None,
    on_item_done: Optional[Callable] = None,
    hook_id: Optional[str] = None,
    cta_always: bool = True,
    countdown_path: Optional[str] = None,
    extra_context: Optional[str] = None,
) -> None:
    """Process a single video item through the full pipeline."""
    async with sem:
        try:
            await step_generate_script(item, on_progress, hook_id=hook_id, extra_context=extra_context)
            await step_generate_tts(item, on_progress)
            await step_speedup_audio(item, on_progress)
            await step_extract_timestamps(item, on_progress)
            await step_write_markup(item, on_progress)
            await step_select_backgrounds(item, on_progress)
            await step_render_video(item, on_progress, cta_always=cta_always,
                                    countdown_path=countdown_path)
            # Clean up temp bg directory
            if item.files.get("bg_dir") and Path(item.files["bg_dir"]).exists():
                shutil.rmtree(item.files["bg_dir"], ignore_errors=True)
                item.files["bg_dir"] = None
            await step_log_result(item, run)
            if on_progress:
                await on_progress(item.id, "done", f"‚úÖ –ì–æ—Ç–æ–≤–æ: {item.title}")
            # Deliver immediately
            if on_item_done:
                await on_item_done(item)
        except Exception as e:
            item.status = "failed"
            item.error = str(e)
            item.timings["failed_at"] = _now()
            if on_progress:
                await on_progress(item.id, "failed", f"‚ùå –û—à–∏–±–∫–∞ ({item.title}): {e}")


async def run_dag(
    count: int = 5,
    format: str = "story",
    hook_id: Optional[str] = None,
    on_progress: Optional[Callable] = None,
    on_item_done: Optional[Callable] = None,
    cta_always: bool = True,
    extra_context: Optional[str] = None,
) -> DagRun:
    """Run the full DAG pipeline.

    Args:
        count: Number of videos to generate.
        format: Video format ("story", "book", "micro", "challenge", "contrast", "debate", "mix").
        hook_id: Specific hook ID from bank (None = auto-generate).
        on_progress: Async callback(item_id, step, message).
        on_item_done: Async callback(item) ‚Äî called immediately when a video is ready.
        extra_context: Optional analytics/insights text to guide LLM generation.

    Returns:
        DagRun with all items and results.
    """
    if format not in VALID_FORMATS:
        raise ValueError(f"Unknown format '{format}'. Valid: {', '.join(sorted(VALID_FORMATS))}")

    # Ensure directories exist
    DATA_DIR.mkdir(exist_ok=True)
    OUTPUT_DIR.mkdir(exist_ok=True)
    DOWNLOADS_DIR.mkdir(exist_ok=True)

    run = DagRun(
        id=f"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        status="running",
        requested_count=count,
        format=format,
        started_at=_now(),
    )

    # Pre-generate countdown video if requested (unique random style each time)
    countdown_path = None
    if hook_id == "countdown":
        if on_progress:
            await on_progress(0, "rendering", "‚è± –†–µ–Ω–¥–µ—Ä—é —Ç–∞–π–º–µ—Ä 5‚Üí0...")
        from styled_subtitles import render_countdown_video
        countdown_path = str(OUTPUT_DIR / "bloom_countdown.mp4")
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(
            None, lambda: render_countdown_video(duration=5.0, output_path=countdown_path, fps=30)
        )
        if on_progress:
            await on_progress(0, "rendering", "‚è± –¢–∞–π–º–µ—Ä –≥–æ—Ç–æ–≤!")
        # Don't pass countdown as hook_id to LLM
        hook_id = None

    # Step 1: Generate ideas
    if on_progress:
        await on_progress(0, "ideas", f"üí° –ì–µ–Ω–µ—Ä–∏—Ä—É—é {count} –∏–¥–µ–π ({format})...")

    ideas = await step_generate_ideas(count, format, hook_id=hook_id, extra_context=extra_context)

    # Assign IDs and create items
    next_id = get_next_id()
    for i, idea in enumerate(ideas):
        item = DagItem(
            id=next_id + i,
            status="idea",
            title=idea.get("title", f"Video {next_id + i}"),
            format=idea.get("format", format),
            hook_type=idea.get("hook_type"),
            idea=idea,
        )
        item.timings["idea_at"] = _now()
        run.items.append(item)

    if on_progress:
        titles = ", ".join(item.title for item in run.items)
        await on_progress(0, "ideas_done", f"üí° –ò–¥–µ–∏ –≥–æ—Ç–æ–≤—ã: {titles}")

    # Steps 2-7: Process items in parallel (max 3)
    sem = asyncio.Semaphore(MAX_PARALLEL)
    await asyncio.gather(*[
        process_item(item, run, sem, on_progress, on_item_done,
                     hook_id=hook_id, cta_always=cta_always,
                     countdown_path=countdown_path,
                     extra_context=extra_context)
        for item in run.items
    ])

    # Finalize
    run.finished_at = _now()
    failed = sum(1 for item in run.items if item.status == "failed")
    run.status = "completed" if failed == 0 else ("failed" if failed == len(run.items) else "partial")

    # Save log
    _save_log(run)

    return run


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def _now() -> str:
    return datetime.now().isoformat(timespec="seconds")


def _save_log(run: DagRun) -> None:
    """Append run to dag_log.json."""
    log_data = {"runs": []}
    if LOG_FILE.exists():
        try:
            log_data = json.loads(LOG_FILE.read_text(encoding="utf-8"))
        except (json.JSONDecodeError, FileNotFoundError):
            pass

    run_dict = {
        "id": run.id,
        "status": run.status,
        "format": run.format,
        "requested_count": run.requested_count,
        "started_at": run.started_at,
        "finished_at": run.finished_at,
        "items": [],
    }
    for item in run.items:
        run_dict["items"].append({
            "id": item.id,
            "status": item.status,
            "title": item.title,
            "format": item.format,
            "hook_type": item.hook_type,
            "source": item.script.get("source") if item.script else None,
            "files": item.files,
            "instagram_caption": item.instagram_caption,
            "error": item.error,
            "timings": item.timings,
        })

    log_data["runs"].append(run_dict)
    LOG_FILE.write_text(json.dumps(log_data, ensure_ascii=False, indent=2), encoding="utf-8")


def _update_catalog(item: DagItem) -> None:
    """Add completed item to scripts_catalog.json."""
    catalog = {"version": "1.0", "description": "–û–¥–æ–±—Ä–µ–Ω–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞", "paths": {}, "scripts": []}
    if CATALOG_FILE.exists():
        try:
            catalog = json.loads(CATALOG_FILE.read_text(encoding="utf-8"))
        except (json.JSONDecodeError, FileNotFoundError):
            pass

    entry = {
        "id": item.id,
        "format": item.format,
        "status": "produced",
        "title": item.title,
        "hook_type": item.hook_type,
        "voice": item.script.get("voice", "Callum") if item.script else "Callum",
        "mood": item.script.get("mood") if item.script else None,
        "tags": item.script.get("tags", []) if item.script else [],
        "audio_file": item.files.get("audio"),
        "timestamps_file": item.files.get("timestamps"),
        "output_file": item.files.get("video"),
        "plain_text": item.plain_text,
        "instagram_caption": item.instagram_caption,
        "produced_at": _now(),
    }

    # Book-specific
    if item.format == "book" and item.script:
        entry["source"] = item.script.get("source")
        entry["image"] = item.script.get("image")
        entry["hook_id"] = item.script.get("hook_id", "bloom_sad_girl")

    catalog.setdefault("scripts", []).append(entry)
    CATALOG_FILE.write_text(json.dumps(catalog, ensure_ascii=False, indent=2), encoding="utf-8")


# ---------------------------------------------------------------------------
# CLI
# ---------------------------------------------------------------------------

async def main():
    import argparse
    parser = argparse.ArgumentParser(description="Bloom Video Production DAG")
    parser.add_argument("--count", "-n", type=int, default=5, help="Number of videos to generate")
    parser.add_argument("--format", "-f", type=str, default="story",
                        choices=["story", "book", "micro", "challenge", "contrast", "debate", "mix"],
                        help="Video format")
    args = parser.parse_args()

    async def cli_progress(item_id, step, message):
        print(f"  [{item_id}] {message}")

    print(f"Starting DAG: {args.count} videos, format={args.format}")
    run = await run_dag(count=args.count, format=args.format, on_progress=cli_progress)

    print(f"\nDAG {run.status}:")
    for item in run.items:
        status_icon = "‚úÖ" if item.status == "done" else "‚ùå"
        print(f"  {status_icon} #{item.id} {item.title} ‚Üí {item.files.get('video', 'N/A')}")
        if item.error:
            print(f"     Error: {item.error}")

    print(f"\nLog saved to: {LOG_FILE}")


if __name__ == "__main__":
    asyncio.run(main())
